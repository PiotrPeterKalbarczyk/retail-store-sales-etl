# ğŸ“Š Retail Store Sales - ETL Pipeline

## ğŸ“ Project: ETL for Retail Sales Data
This project demonstrates a simple **ETL (Extract, Transform, Load)** process for retail sales data. The data is extracted from a CSV file, cleaned and transformed using Python, and then loaded into a PostgreSQL database.

---

## ğŸ”¹ 1. EXTRACT (Data Extraction)
âœ… Load data from `retail_store_sales.csv` into a Pandas DataFrame.
âœ… Perform basic data analysis (`head()`, `info()`, `describe()`).

---

## ğŸ”¹ 2. TRANSFORM (Data Cleaning and Preparation)
âœ… Remove duplicates.
âœ… Standardize column names (lowercase, replace spaces with `_`).
âœ… Convert `transaction_date` to `datetime` format.
âœ… Handle missing values:
   - Fill `price_per_unit` using the first available value for each `item`.
   - Calculate `total_spent` as `price_per_unit * quantity`.
   - Fill missing values in `discount_applied` with `No`.
âœ… Remove rows where `item` is `NaN`.

---

## ğŸ”¹ 3. LOAD (Loading Data into PostgreSQL)
âœ… Connect to PostgreSQL using `SQLAlchemy`.
âœ… Create a table if it does not exist.
âœ… Load data into PostgreSQL using `to_sql()`.

ğŸ“Œ **Note:** Database credentials (username, password) are not hardcoded in the script and must be provided manually.

---

## ğŸš€ How to Run the Project
### 1ï¸âƒ£ Install Required Dependencies
First, install the dependencies:
```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Run the Jupyter Notebook
```bash
jupyter notebook retail_sales.ipynb
```

---

## ğŸ“¦ Technologies Used
- **Python** (pandas, SQLAlchemy)
- **PostgreSQL** (local database)
- **Jupyter Notebook** (for documenting the ETL process)

---

## ğŸ“Œ Possible Extensions
âœ… Add SQL-based data analysis.
âœ… Visualize results in Tableau / Power BI.
âœ… Automate data extraction from an API.


